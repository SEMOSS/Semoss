nl_search<-function(txt,db,joins=data.frame(),filename="unique-values-table.rds",basic=TRUE){
	if(basic){
		p<-nliapp_mgr_basic(txt,db,joins,filename)
	}else{
		p<-nliapp_mgr_comprehensive(txt,db,joins,filename)
	}
	return(p)
}

nliapp_mgr_comprehensive<-function(txt,db,joins=data.frame(),filename="unique-values-table.rds"){
	library(data.table)
	library(plyr)
	library(udpipe)
	library(stringdist)
	library(igraph)
	library(SteinerNet)
		
	r<-data.table(Response=character(),AppID=character(),Statement=character())
	p<-data.table(label=character(),appid=character(),appid2=character(),part=character(),item1=character(),item2=character(),item3=character(),item4=character(),item5=character(),item6=character(),item7=character(),phase=integer(),pick=character())
	
	db$Table<-paste(db$AppID,db$Table,sep="._.")
	joins$tbl1<-paste(joins$AppID,joins$tbl1,sep="._.")
	joins$tbl2<-paste(joins$AppID,joins$tbl2,sep="._.")
	joins$AppID2<-joins$AppID
	# save the original db
	db_in<-db
	
	# identify multip words column names
	txt<-db_match_extension(txt,db$Column)
	df_in<-parse_question_mgr(txt)

	if(length(unique(db$AppID))>1){
		refined_df<-filter_apps(df_in,db)
		apps<-refined_df[[1]]
		
		# establish repository across the apps
		global_apps<-refined_df[[3]]
		global_db<-refined_df[[2]]
		# add links across the apps
		if(length(global_apps)>1){
			global_joins<-joins[joins$AppID %in% global_apps,]
			# get inter apps links and add to the joins if exist
			ext_links<-get_ext_links(global_db)
			if(nrow(ext_links)>0){
				global_joins<-rbind(global_joins,ext_links)
			}
			out<-sift_apps_ext(global_db,global_joins)
			global_db<-out[[1]]
			global_joins<-out[[2]]
			db<-global_db[global_db$AppID %in% apps,]
		}else{
			db<-global_db[global_db$AppID %in% apps,]
			global_db<-data.frame()
			global_joins<-data.frame()
		}
		# setup individual repositories
		max_freq<-refined_df[[4]]
	}else{
		# no global
		refined_df<-filter_apps(df_in,db)
		db<-refined_df[[2]]
		apps<-unique(db$AppID)
		global_db<-data.frame()
		global_joins<-data.frame()
	}
	
	# now we hve two loops
	# 1 - all apps separately
	# 2 - linked relevant apps as a single app 
	# Note: processing from... pixel separate app and table
	N<-length(apps)
	M<-ifelse(nrow(global_db),1,0)
	if((N+M)>0){
		if(file.exists(filename)){
			db_values<-readRDS(filename)
		}else{
			db_values<-data.frame(AppID=character(),Table=character(),Column=character(),Values=character(),stringsAsFactors=FALSE)
		}
		
		for(i in 1:(N+M)){
			if(i<=N){	
				# prepare individual apps
				cur_app<-apps[i]
				cur_db<-db[db$AppID==apps[i],]
				cur_values<-db_values[db_values$AppID==apps[i],]
				if(nrow(joins)!=0){
					cur_joins<-joins[joins$AppID==apps[i],]
				}else{
					cur_joins<-joins
				}
				out<-sift_apps_ext(cur_db,cur_joins)
				cur_db<-out[[1]]
				cur_joins<-out[[2]]
			}else{
				# prepare combined apps
				cur_app<-"combined"
				cur_values<-db_values[db_values$AppID %in% global_apps,]
				cur_db<-global_db
				cur_joins<-global_joins
			}
			# process a single app
			app_out<-process_app(cur_app,df_in,cur_db,cur_joins,cur_values)
			r<-rbindlist(list(r,app_out[[1]]))
			phased_pixel<-app_out[[2]]
			if(nrow(phased_pixel)>0){
				p<-rbind(p,phased_pixel)
			}
		}
	}else{
		r<-rbindlist(list(r,list("Error","","Rephrase the request: no applicable databases found")))
	}
	# keep only query object if at least one of the results is proper
	if(nrow(r[r$Response == "SQL",])==0){
		p<-data.table(appid=character(),part=character(),item1=character(),item2=character(),item3=character(),item4=character(),item5=character(),item6=character(),item7=character())
		n<-nrow(r)
		if(n>0){
			for(i in 1:n){
				p<-rbindlist(list(p,list(r$AppID[i],r$Response[i],r$Statement[i],"","","","","","")))
			}
		}
	}
	gc()
	# for debugging purposes only!!!
	write.csv(p,file="query_object.csv")
	return(p)
}
nliapp_mgr_basic<-function(txt,db,joins=data.frame(),filename="unique-values-table.rds"){
	library(data.table)
	library(plyr)
	library(udpipe)
	library(stringdist)
	library(igraph)
	library(SteinerNet)
		
	r<-data.table(Response=character(),AppID=character(),Statement=character())
	p<-data.table(label=character(),appid=character(),appid2=character(),part=character(),item1=character(),item2=character(),item3=character(),item4=character(),item5=character(),item6=character(),item7=character(),phase=integer(),pick=character())
	
	db$Table<-paste(db$AppID,db$Table,sep="._.")
	joins$tbl1<-paste(joins$AppID,joins$tbl1,sep="._.")
	joins$tbl2<-paste(joins$AppID,joins$tbl2,sep="._.")
	joins$AppID2<-joins$AppID
	# save the original db
	db_in<-db
	
	# identify multip words column names
	txt<-db_match_extension(txt,db$Column)
	df_in<-parse_question_mgr(txt)
	# get all appids used in the request
	refined_df<-filter_apps(df_in,db)
	global_apps<-refined_df[[3]]
	global_db<-refined_df[[2]]
	N<-length(global_apps)
	if(N>1){
		# multiple db relevant
		# add links across the apps
		global_joins<-joins[joins$AppID %in% global_apps,]
		# get inter apps links and add to the joins if exist
		ext_links<-get_ext_links(global_db)
		if(nrow(ext_links)>0){
			global_joins<-rbind(global_joins,ext_links)
		}
		out<-sift_apps_ext(global_db,global_joins)
		global_db<-out[[1]]
		global_joins<-out[[2]]
	}else if(N==1){
		# no global
		apps<-global_apps
		db<-global_db[global_db$AppID==apps,]
		global_db<-data.frame()
		global_joins<-data.frame()
	}else{
		apps<-vector()
	}
	if(file.exists(filename)){
		db_values<-readRDS(filename)
	}else{
		db_values<-data.frame(AppID=character(),Table=character(),Column=character(),Values=character(),stringsAsFactors=FALSE)
	}
	if(N>0){
		if(N==1){	
			# Run a single app
			cur_app<-apps
			cur_db<-db
			cur_values<-db_values[db_values$AppID==apps,]
			if(nrow(joins)!=0){
				cur_joins<-joins[joins$AppID==apps,]
			}else{
				cur_joins<-joins
			}
			out<-sift_apps_ext(cur_db,cur_joins)
			cur_db<-out[[1]]
			cur_joins<-out[[2]]
		}else{
			# prepare combined apps
			cur_app<-"combined"
			cur_values<-db_values[db_values$AppID %in% global_apps,]
			cur_db<-global_db
			cur_joins<-global_joins
		}
		# process app either a single ir combined
		app_out<-process_app(cur_app,df_in,cur_db,cur_joins,cur_values)
		r<-rbindlist(list(r,app_out[[1]]))
		phased_pixel<-app_out[[2]]
		if(nrow(phased_pixel)>0){
			p<-rbind(p,phased_pixel)
		}
	}else{
		r<-rbindlist(list(r,list("Error","","Rephrase the request: no applicable databases found")))
	}
	# keep only query object if at least one of the results is proper
	if(nrow(r[r$Response == "SQL",])==0){
		p<-data.table(appid=character(),part=character(),item1=character(),item2=character(),item3=character(),item4=character(),item5=character(),item6=character(),item7=character())
		n<-nrow(r)
		if(n>0){
			for(i in 1:n){
				p<-rbindlist(list(p,list(r$AppID[i],r$Response[i],r$Statement[i],"","","","","","")))
			}
		}
	}
	gc()
	# for debugging purposes only!!!
	write.csv(p,file="query_object.csv")
	return(p)
}

grp_cnt<-function(grp,mydb){
	words<-unique(mydb[mydb$Table %in% grp,"Word"])
	words<-words[nchar(words)>0]
	return(length(words))
}

sift_apps_ext<-function(db,joins){
	library(igraph)
	db<-db[order(db$Word,-db$Score),]
	# construct graph from edges
	g<-graph_from_edgelist(as.matrix(joins[,1:2]),directed=FALSE)
	# identify connected components
	clu<-components(g,mode="weak")
	grps<-groups(clu)
	
	# count number of columns from the request in each group of connected tables and select groups with max
	cnt<-unlist(lapply(grps,grp_cnt,db))
	if(length(cnt)>0){
		max_cnt<-max(cnt)
	}else{
		max_cnt<-0
	}
	ind<-which(cnt==max_cnt)
	if(length(ind)>0){
		mytbls<-unlist(grps[ind])
	}else{
		mytbls<-vector()
	}
	# count number of columns from the request in single tables
	joins_tbls<-unique(c(joins$tbl1,joins$tbl2))
	singles<-unique(db[!(db$Table %in% joins_tbls) & db$Score>0,"Table"])
	singles_cnt<-unlist(lapply(singles,grp_cnt,db))
	if(length(singles_cnt)>0){
		max_singles_cnt<-max(singles_cnt)
	}else{
		max_singles_cnt<-0
	}
	ind<-which(singles_cnt>=max_cnt & singles_cnt==max_singles_cnt)
	if(length(ind)>0){
		mytbls<-append(mytbls,singles[ind])
	}

	# filter db and joins based on the retained tables
	mydb<-db[db$Table %in% mytbls,]
	myjoins<-joins[joins$tbl1 %in% mytbls | joins$tbl2 %in% mytbls,]
	
	myList<-list()
	myList[[1]]<-mydb
	myList[[2]]<-myjoins
	gc()
	return(myList)
}


get_ext_links<-function(db,threshold=0.925){
	apps<-unique(db$AppID)
	n<-length(apps)
	ext_links<-data.frame(tbl1=character(),tbl2=character(),joinby1=character(),joinby2=character(),AppID=character(),AppID2=character(),stringsAsFactors = FALSE)
	if(n>1){
		for(i in 1:(n-1)){
			db1<-db[db$AppID==apps[i],]
			db1_cols<-unique(db1[tolower(db1$Key)=="true",]$Column)
			for(j in (i+1):n){
				db2<-db[db$AppID==apps[j],]
				db2_cols<-unique(db2[tolower(db2$Key)=="true",]$Column)
				for(k in 1:length(db1_cols)){
					matches<-stringsim(tolower(db1_cols[k]),tolower(db2_cols),method='jw', p=0.1)
					ind<-which(matches>=threshold)
					if(length(ind)>0){
						db1_rec<-db1[db1$Column==db1_cols[k],]
						db2_rec<-db2[db2$Column %in% db2_cols[ind],]
						P<-nrow(db1_rec)
						Q<-nrow(db2_rec)
						if(P>0 & Q>0){
							for(p in 1:P){
								for(q in 1:Q){
									rec<-list(tbl1=db1_rec$Table[p],tbl2=db2_rec$Table[q],joinby1=db1_rec$Column[p],joinby2=db2_rec$Column[q],AppID=db1_rec$AppID[p],AppID2=db2_rec$AppID[q])
									ext_links<-rbind(ext_links,rec,stringsAsFactors=FALSE)
								}
							}
						}
					}
				}
					
			}
		}
	}
	return(ext_links)
}

get_bridge_select<-function(combined_pixel,pixel_inter){
	rec<-data.frame()
	first_inter<-combined_pixel[combined_pixel$part=="from" & (combined_pixel$appid == pixel_inter$appid | combined_pixel$appid2 == pixel_inter$appid) & (combined_pixel$item1 == pixel_inter$item1 | combined_pixel$item3 == pixel_inter$item1),]
	if(nrow(first_inter)>0){
		rec<-first_inter[1,]
		rec$part<-"select"
		rec$appid2<-""
		rec$item1<-pixel_inter$item1
		rec$item2<-pixel_inter$item2
		rec$item3<-""
		rec$item4<-""
		rec2<-pixel_inter
		rec2$part<-"select"
		rec2$appid<-pixel_inter$appid2
		rec2$appid2<-""
		rec2$item1<-pixel_inter$item3
		rec2$item2<-pixel_inter$item4
		rec2$item3<-""
		rec2$item4<-""
		inter_rec<-rbind(rec2,pixel_inter)
	}else{
		second_inter<-combined_pixel[combined_pixel$part=="from" & (combined_pixel$appid == pixel_inter$appid2 | combined_pixel$appid2 == pixel_inter$appid2) & (combined_pixel$item1 == pixel_inter$item3 | combined_pixel$item3 == pixel_inter$item3),]
		rec<-second_inter[1,]
		rec$part<-"select"
		rec$appid2<-""
		rec$item1<-pixel_inter$item3
		rec$item2<-pixel_inter$item4
		rec$item3<-""
		rec$item4<-""
		rec2<-pixel_inter
		rec2$part<-"select"
		rec2$appid<-pixel_inter$appid
		rec2$appid2<-""
		rec2$item1<-pixel_inter$item1
		rec2$item2<-pixel_inter$item2
		rec2$item3<-""
		rec2$item4<-""
		inter_rec<-rbind(rec2,pixel_inter)
	}
	myList<-list()
	myList[[1]]<-rec
	myList[[2]]<-inter_rec
	return(myList)
}

pick_exec_order<-function(appid,joins,pixel){
	pixel$phase<-1
	pixel$pick<-""
	pixel[pixel$part=="select","pick"]<-"yes"
	if(appid=="combined" & nrow(joins)>0){
		combined_pixel<-pixel[0,]
		# joins for for individual apps
		joins_sep<-joins[joins$AppID == joins$AppID2,]
		joins_inter<-joins[joins$AppID != joins$AppID2,]
		if(nrow(joins) > nrow(joins_sep)){
			# separate pixel into pixel group and the rest of pixel
			pixel_group<-pixel[pixel$part == "group",]
			pixel_having<-pixel[pixel$part == "having",]
			pixel<-pixel[!(pixel$part %in% c("group","having")),]
			# get a data frame with all trees in the app joins
			all_trees<-get_all_trees(joins_sep)
			# get count of trees in the apps and nodes in the trees
			all_trees_cnt<-get_all_trees_cnt(all_trees)
			all_trees_cnt$Processed<-"no"
			all_trees_cnt$InterID<-0
			# add joins id and processed flag
			joins_inter$InterID<-seq(nrow(joins_inter))
			joins_inter$Processed<-"no"
			cur_joins_inter<-joins_inter
			N<-nrow(all_trees_cnt)
			k<-1
			for(i in 1:N){
				# cur_trees_cnt list not processed trees only
				cur_trees_cnt<-all_trees_cnt[all_trees_cnt$Processed=="no",]
				# cur_joins_inter are not processed hoins yet
				cur_joins_inter<-joins_inter[joins_inter$Processed=="no",]
				r<-get_next_tree(all_trees,all_trees_cnt,cur_trees_cnt,cur_joins_inter)

				# if exists inter tree item process it
				if(length(r)==2){
					next_inter<-r[2]
					# extract from pixel rows connecting two trees
					pixel_inter<-get_pixel_intertree(pixel,joins_inter,next_inter)
					out<-get_bridge_select(combined_pixel,pixel_inter)
					bridge_select<-out[[1]]
					inter_select<-out[[2]]
					if(nrow(bridge_select)>0){
						combined_pixel<-rbind(combined_pixel,bridge_select)
					}
					pixel_inter$phase<-k
					inter_select$phase<-k
					k<-k+1
					combined_pixel<-rbind(combined_pixel,inter_select)
					joins_inter[joins_inter$InterID==next_inter,"Processed"]<-"yes"
				}
				next_tree<-r[1]
				# extract from pixel rows connecting tables inside a single tree
				pixel_db<-get_pixel_intratree(pixel,all_trees,next_tree)
				
				# indicate the execution phase 
				pixel_db$phase<-k
				k<-k+1
				combined_pixel<-rbind(combined_pixel,pixel_db)
				all_trees_cnt[all_trees_cnt$TreeID==next_tree,"Processed"]<-"yes"
				# record next inter if available
				if(length(r)==2){
					all_trees_cnt[all_trees_cnt$TreeID==next_tree,"InterID"]<-next_inter
				}
			}
			# remove duplicates if there are any
			combined_pixel<-combined_pixel[!duplicated(combined_pixel[,1:11]),]
			myorder<-data.frame(part=c("select","from","where","group","having"),stringsAsFactors=FALSE)
			combined_pixel<-combined_pixel[order(combined_pixel$phase,match(combined_pixel$part,myorder$part)),]
			ind<-which(pixel$pick=="yes")
			if(length(ind)>0){
				for(i in 1:length(ind)){
					combined_pixel[combined_pixel$appid == pixel$appid[i] & combined_pixel$part=="select" & combined_pixel$part == pixel$part[i] & 
					combined_pixel$item1 == pixel$item1[i] & combined_pixel$item2 == pixel$item2[i],"pick"]<-"yes"
				}
			}
			# append pixel group if exists
			if(nrow(pixel_group)>0){
				pixel_group$phase<-k
				combined_pixel<-rbind(combined_pixel,pixel_group)
				if(nrow(pixel_having)>0){
					pixel_having$phase<-k
					combined_pixel<-rbind(combined_pixel,pixel_having)
				}
			}
		}else{
			combined_pixel<-pixel
		}
	}else{
		combined_pixel<-pixel
	}
	gc()
	return(combined_pixel)
}

get_pixel_intratree<-function(pixel,all_trees,next_tree){
	pixel<-as.data.frame(pixel)
	phase_nodes<-all_trees[all_trees$TreeID==next_tree,]
	appid<-phase_nodes$AppID[1]
	tbls<-unique(unlist(strsplit(phase_nodes$Vertex,"._.",fixed=TRUE))[c(FALSE,TRUE)])
	# get select items
	ind<-which(pixel$appid==appid & pixel$part=="select" & pixel$item1 %in% tbls)
	phase_df<-pixel[ind,]
	# get from items
	from_df<-pixel[pixel$part=="from" & pixel$appid==appid & pixel$appid2=="" & pixel$item1 %in% tbls,]
	phase_df<-rbind(phase_df,from_df)
	from_df<-pixel[pixel$part=="from" & pixel$appid==appid & pixel$appid2==appid & pixel$item1 %in% tbls & pixel$item3 %in% tbls,]
	phase_df<-rbind(phase_df,from_df)
	
	# get where items
	where_df1<-pixel[pixel$part=="where" & pixel$appid==appid & pixel$appid2=="" & pixel$item1 %in% tbls,]
	where_df2<-pixel[pixel$part=="where" & pixel$appid==appid & pixel$item1 %in% tbls & pixel$appid2==appid & pixel$item4 %in% tbls,]
	phase_df<-rbind(phase_df,where_df1)
	phase_df<-rbind(phase_df,where_df2)
	# get group items
	group_df<-pixel[pixel$part=="group" & pixel$appid==appid & pixel$item1 %in% tbls,]
	phase_df<-rbind(phase_df,group_df)
	# get having items
	having_df1<-pixel[pixel$part=="having" & pixel$appid==appid & pixel$appid2=="" & pixel$item1 %in% tbls,]
	having_df2<-pixel[pixel$part=="having" & pixel$appid==appid & pixel$item1 %in% tbls & pixel$appid2==appid & pixel$item5 %in% tbls,]
	phase_df<-rbind(phase_df,having_df1)
	phase_df<-rbind(phase_df,having_df2)
	gc()
	return(phase_df)
}

get_pixel_intertree<-function(pixel,joins_inter,next_inter){
	pixel<-as.data.frame(pixel)
	rec<-joins_inter[joins_inter$InterID==next_inter,]
	comp1<-unlist(strsplit(rec$tbl1,"._.",fixed=TRUE))
	comp2<-unlist(strsplit(rec$tbl2,"._.",fixed=TRUE))
	pixel_phase<-pixel[pixel$appid==comp1[1] & pixel$item1==comp1[2] & pixel$appid2==comp2[1] & pixel$item3==comp2[2] |
		pixel$appid==comp2[1] & pixel$item1==comp2[2] & pixel$appid2==comp1[1] & pixel$item3==comp1[2],]
	return(pixel_phase)
}


get_next_tree<-function(all_trees,all_trees_cnt,cur_trees_cnt,cur_joins_inter){
	if(all(all_trees_cnt$Processed=="no")){
		# when no trees processed take the first one
		out<-cur_trees_cnt$TreeID[1]
	}else{
		out<-vector()
		# n - number of unprocessed trees
		n<-nrow(cur_trees_cnt)
		# m - number of unprocessed inter joins
		m<-nrow(cur_joins_inter)
		# cur_vertices - all vertices that already processed
		cur_vertices<-all_trees[!(all_trees$TreeID %in% cur_trees_cnt$TreeID),]$Vertex	
		for(i in 1:n){
			# fut_vertices - all verticeses in the next potential tree
			fut_vertices<-all_trees[all_trees$TreeID %in% cur_trees_cnt$TreeID[i],]$Vertex
			for(j in 1:m){
				if(cur_joins_inter$tbl1[j] %in% cur_vertices & cur_joins_inter$tbl2[j] %in% fut_vertices | cur_joins_inter$tbl2[j] %in% cur_vertices & cur_joins_inter$tbl1[j] %in% fut_vertices){
					out[1]<-cur_trees_cnt$TreeID[i]
					out[2]<-cur_joins_inter$InterID[j]
					break
				}
			}
			if(length(out)==2){
				break
			}
		}
	}
	gc()
	return(out)
}

get_all_trees<-function(joins_sep){
	library(igraph)
	g<-graph_from_edgelist(as.matrix(joins_sep[,1:2]),directed=FALSE)
	g1<-mst(g)
	# use components/group
	tree_membership<-components(g1)$membership
	all_trees<-data.frame(TreeID=integer(),Vertex=character(),stringsAsFactors=FALSE)
	for(i in 1:max(tree_membership)){
		cur_tree<-data.frame(Vertex=names(tree_membership[tree_membership==i]),stringsAsFactors=FALSE)
		cur_tree$TreeID<-i
		cur_tree<-cur_tree[,c(2,1)]
		all_trees<-rbind(all_trees,cur_tree)
	}
	all_trees$AppID<-unlist(strsplit(all_trees$Vertex,"._.",fixed=TRUE))[c(TRUE,FALSE)]
	gc()
	return(all_trees)
}

get_all_trees_cnt<-function(all_trees){
	library(plyr)
	all_trees_cnt<-count(all_trees,c("AppID","TreeID"))
	names(all_trees_cnt)[3]<-"TreeOrder"
	lookup<-count(all_trees_cnt[,1:2],c("AppID"))
	# this table critical for the ordering execution
	all_trees_cnt$TreeCnt<-lookup$freq[match(unlist(all_trees_cnt$AppID),lookup$AppID)]
	# order app tree count ascending and tree order descending
	all_trees_cnt<-all_trees_cnt[order(all_trees_cnt$TreeCnt,-all_trees_cnt$TreeOrder),]
	gc()
	return(all_trees_cnt)
}

# process single app
process_app<-function(appid,df_in,cur_db,cur_joins,cur_values){
	r<-data.table(Response=character(),AppID=character(),Statement=character())
	# current appid only used to fill in the final results
	
	# Prepare request for current db
	df<-parse_request(df_in,cur_db)
	
	# get columns used in the request
	cols<-as.character(df[df$itemtype == "column","item"])
	# If no columns present skip this app
	exec_order<-data.frame()
	if(length(cols)>0){
	
		# get from clause (joins)
		# If required tables not found or not connected move to the next app
		out<-join_clause_mgr(cols,cur_db,cur_joins)
		if(out[[1]]!=""){
			sql<-out[[1]]
			response<-"Error"
		}else{
			from_clause<-out[[2]]
			from_joins<-unique(out[[3]])
			request_tbls<-unique(c(from_joins$tbl1,from_joins$tbl2))
			request_tbls<-request_tbls[request_tbls!=""]
			exec_order<-out[[4]]
	
			# Start constructing the query object
			df$processed<-"no"
			out<-get_start(df)
			if(length(out)==1){
				if(!is.null(out[[1]])){
					select_part<-get_select(out[[1]])
					out<-join_clause_mgr(cols,cur_db,cur_joins)
					if(out[[1]]==""){
						from_clause<-out[[2]]
						from_joins<-unique(out[[3]])
						pixel_from<-build_pixel_from(from_joins)
						request_tbls<-unique(c(from_joins$tbl1,from_joins$tbl2))
						request_tbls<-request_tbls[request_tbls!=""]
						response<-"SQL"
					}else{
						sql<-out[[1]]
						response<-"Error"
						next
					}
					pixel_single_select<-build_pixel_single_select(select_part,request_tbls,cur_db)
					pixel_aggr_select<-data.frame()
					pixel_where<-data.frame()
					pixel_group<-data.frame()
					pixel_having<-data.frame()
				}else{
					response<-"Error"
					sql<-"Rephrase the request"
				}
			}else{
				if(!is.null(out[[1]]) & !is.null(out[[2]])){
					select_part<-get_select(out[[1]])
					mypart<-get_where(out[[2]],request_tbls,cur_joins,cur_values)
					if(length(mypart[[5]])>0){
						cols<-append(cols,mypart[[5]])
						out<-join_clause_mgr(cols,cur_db,cur_joins)
						if(out[[1]]==""){
							from_clause<-out[[2]]
							from_joins<-unique(out[[3]])
							pixel_from<-build_pixel_from(from_joins)
							request_tbls<-unique(c(from_joins$tbl1,from_joins$tbl2))
							request_tbls<-request_tbls[request_tbls!=""]
							response<-"SQL"
						}else{
							sql<-out[[1]]
							response<-"Error"
							next
						}
					}else{
						pixel_from<-build_pixel_from(from_joins)
						request_tbls<-unique(c(from_joins$tbl1,from_joins$tbl2))
						request_tbls<-request_tbls[request_tbls!=""]
						response<-"SQL"
					}
					
					
					where_part<-mypart[[1]]
					having_part<-mypart[[3]]
					mypart1<-validate_select(select_part,mypart[[2]])
					# append misfits from having clause
					select_aggr<-append(mypart1[[1]],mypart[[4]])
					select_part<-mypart1[[2]]
					group_part<-mypart1[[3]]
					# if groupping present then all non aggregate select should be in groups
					# aggregates from having clause place in the select to make the results easier to understand
					if(length(having_part)>0){
						group_part<-unique(append(group_part,select_part))
						select_aggr<-select_having(having_part)
					}
					# add to select section all group columns if they are not there
					if(length(group_part)>0){
						select_part<-unique(append(group_part,select_part))
					}			
					
					# add where columns into select section
					if(length(where_part)>0){
						# if we do not have aggregate columns we can add columns from where to the select section
						if(length(select_aggr)==0){
							select_part<-unique(append(select_part,select_where(where_part,request_tbls,cur_db)))
						}
					}
					pixel_where<-build_pixel_where(where_part,request_tbls,cur_db)
					pixel_group<-build_pixel_group(group_part,request_tbls,cur_db)
					
					select_aggr<-get_alias(select_aggr)
					pixel_aggr_select<-build_pixel_aggr_select(select_aggr,request_tbls,cur_db)
					
					pixel_single_select<-build_pixel_single_select(select_part,request_tbls,cur_db)
					# Initially it is an empty clause
					pixel_having<-build_pixel_having(having_part,request_tbls,cur_db)
				}
			}
		}
		# complete building sql and pixel objects
		if(response == "SQL"){
			sql<-"Correct sql"
			r<-rbindlist(list(r,list("SQL",appid,"Correct SQL")))
			pixel<-build_pixel(appid,pixel_aggr_select,pixel_single_select,pixel_where,pixel_group,pixel_having,pixel_from)
			phased_pixel<-pick_exec_order(appid,exec_order,pixel)
		}else{
			r<-rbindlist(list(r,list(response,as.character(appid),sql)))
			phased_pixel<-data.frame()
		}
		
	}else{
		r<-rbindlist(list(r,list("Error","","Rephrase the request: no applicable databases found")))
		phased_pixel<-data.frame()
	}
	myList<-list()
	myList[[1]]<-r
	myList[[2]]<-phased_pixel
	gc()
	return(myList)
}

get_max_seq<-function(idx){
	mydif<-diff(idx)
	if(length(mydif)==1){
		if(mydif[1]==1){
			myidx=idx
		}else{
			myidx<-0
		}
	}else{
		mydif[mydif>1]<-0
		x<-which(mydif==0)
		y<-0
		y<-append(y,x)
		y[length(y)+1]<-length(mydif)+1
		z<-diff(y)
		p<-which(z==max(z))[1]
		myidx<-idx[y[p]+1]:idx[y[p+1]]
	}
	return(myidx)
}

db_match_extension<-function(txt,cols){
	words<-unlist(strsplit(txt," "))
	out<-words
	n<-length(words)
	library(plyr)
	if(n>0){
		df<-data.frame(word=character(),idx=numeric(),stringsAsFactors=FALSE)
		for(i in 1:n){
			# skip words in single quotes
			if(substr(words[i],1,1)!="'" & substr(words[i],nchar(words[i]),nchar(words[i]))!="'"){
				word_idx<-grep(tolower(words[i]),tolower(cols))
				if(length(word_idx>0)){
					mydf<-data.frame(idx=word_idx,stringsAsFactors=FALSE)
					mydf$word<-words[i]
					df<-rbind(df,mydf)
				}
			}
		}
		x<-count(df,"idx")
		x<-x[x$freq>1,]
		if(nrow(x)>0){
			candidates<-cols[x$idx]
			n<-length(candidates)
			for(i in 1:n){			
				singles<-unique(df[df$idx %in% x$idx[i],]$word)
				seq_idx<-which(out %in% singles)
				if(length(seq_idx)>0){
					seq_idx<-seq_idx[order(seq_idx)]
					seq_idx<-get_max_seq(seq_idx)
					
					if(length(seq_idx)>1){
						m<-length(seq_idx)
						candidate<-tolower(candidates[i])
						for(j in seq_idx){	
							candidate<-gsub(tolower(words[j]),"",candidate)
						}
						candidate<-gsub("[[:punct:]]","",candidate)
						if(nchar(candidate)==0){
							# Found multiple words column
							out[seq_idx]<-""
							out[seq_idx[1]]<-candidates[i]
						}
					}
				}
			}
		}
	}
	out<-out[out!=""]
	mytxt<-paste(out,collapse=" ")
	gc()
	return(mytxt)
}

get_alias<-function(items){
	n<-length(items)
	repl<-vector()
	if(n>0){
		for(i in 1:n){
			pos1<-unlist(gregexpr(pattern="[(]",items[i]))
			if(length(pos1)>0){
				pos2<-unlist(gregexpr(pattern="[)]",items[i]))
				if(length(pos2)>0){
					repl[i]<-paste0(items[i]," as ",substr(items[i],1,pos1-1),"_of_",substr(items[i],pos1+1,pos2-1))
				}
			}
		}
	}
	return(repl)
}

select_having<-function(having_part){
	items<-unlist(strsplit(having_part," "))
	ind<-which(tolower(substr(items,1,3)) %in% c("uni","sum","max","min","avg"))
	return(items[ind])
}

select_where<-function(where_part,request_tbls,cur_db){
	items<-vector()
	n<-length(where_part)
	for(i in 1:n){
		x<-trim(unlist(strsplit(where_part[i]," ")))
		if(length(x)==3){
			items<-append(items,select_where_helper(x[1],request_tbls,cur_db))
			items<-append(items,select_where_helper(x[3],request_tbls,cur_db))		
		}else if(length(x)==5){
			items<-append(items,select_where_helper(x[1],request_tbls,cur_db))
			items<-append(items,select_where_helper(x[3],request_tbls,cur_db))		
			items<-append(items,select_where_helper(x[5],request_tbls,cur_db))	
		}
	}
	gc()
	return(items)
}

select_where_helper<-function(item,request_tbls,cur_db){
	selected<-vector()
	tbls<-cur_db[tolower(cur_db$Column) == tolower(item) & tolower(cur_db$Table) %in% tolower(request_tbls),"Table"]
	if(length(tbls)>0){
		selected<-item
	}
	return(selected)
}

validate_select<-function(select_part,group_part){
	ind<-which(tolower(substr(select_part,1,3)) %in% c("uni","sum","max","min","avg"))
	if(length(ind)>0){
		select_aggr<-select_part[select_part %in% select_part[ind]]
		select_group<-select_part[!(select_part %in% select_part[ind])]
		select_part<-select_group
		if(length(select_group)>0){
			group_part<-unique(append(group_part,select_group))
		}
	}else{
		select_aggr<-vector()
		if(length(group_part)>0){
			select_part<-unique(append(select_part,group_part))
			group_part<-vector()
		}
	}
	myList<-list()
	myList[[1]]<-select_aggr
	myList[[2]]<-select_part
	myList[[3]]<-group_part
	gc()
	return(myList)
}


get_conj<-function(parsed_df,kids){
	conj<-vector()
	kids2<-kids[kids$dep_rel=="conj" & kids$itemtype=="column",]
	if(nrow(kids2)>0){
		for(i in 1:nrow(kids2)){
			if(nrow(parsed_df[parsed_df$head_token_id==kids2$token_id[i] & tolower(parsed_df$token)=="and",])>0){
				if(i==1){
					conj<-kids2$token_id[i]
				}else{
					conj<-append(conj,kids2$token_id[i])
				}	
			}
		}
	}
	return(as.integer(conj))
}

get_start<-function(parsed_df){
	out<-list()
	out[[1]]<-NULL
	out[[2]]<-NULL
	root<-parsed_df[parsed_df$head_token_id==0,]
	if(root$itemtype=="column"){
		# Identify possible select nodes
		kids<-parsed_df[parsed_df$head_token_id==root$token_id,]
		select_tree<-kids[!(kids$dep_rel %in% c("nmod","obj","acl","obl","conj","acl:relcl")) & (kids$xpos != "JJR" | kids$dep_rel %in% "amod"),]
		# additional nodes using conjunction
		r<-get_conj(parsed_df,kids)
		if(nrow(select_tree)>0){
			r<-append(as.integer(select_tree$token_id),r)
		}
		out[[1]]<-rbind(root,get_subtree(parsed_df,r,"nmod"))
		where_tree<-parsed_df[!(parsed_df$token_id %in% out[[1]]$token_id),]	
		out[[2]]<-where_tree
	}else{
		kids<-parsed_df[parsed_df$head_token_id==root$token_id,]
		
		nsubj<-kids[substr(kids$dep_rel,1,5)=="nsubj" & kids$itemtype=="column",]
		if(nrow(nsubj)==0){
			nsubj<-kids[substr(kids$dep_rel,1,5)!="obj" & kids$itemtype=="column",]
		}
		obj<-kids[!(kids$token_id %in% nsubj$token_id),]
		if(nrow(nsubj)>0){
			# Identify possible select nodes
			out[[1]]<-get_subtree(parsed_df,as.integer(nsubj$token_id))
			if(nrow(obj)>0){
				# Identify possible select nodes
				#out[[2]]<-get_subtree(parsed_df,as.integer(obj$token_id))
				# include root
				out[[2]]<-rbind(root,get_subtree(parsed_df,as.integer(obj$token_id)))
			}
		}
	}
	return(out)
}

get_select<-function(select_df){
	select_part<-vector()
	select_df$processed="no"
	token_id<-select_df[select_df$itemtype=="column",]$token_id
	if(length(token_id)>0){
		for(i in 1:length(token_id)){
			aggr_df<-select_df[select_df$head_token_id==token_id[i] & !(select_df$token_id %in% token_id) & tolower(select_df$token) %in% c("total","average","highest","lowest","best","worst","many") & select_df$processed=="no",]
			if(nrow(aggr_df)>0){
				count_df<-select_df[select_df$head_token_id==token_id[i] & !(select_df$token_id %in% token_id) & tolower(select_df$token) %in% c("many") & select_df$processed=="no",]
				if(nrow(count_df)>0){
					if(tolower(count_df$token[1]) == "many"){
						child<-select_df[select_df$head_token_id==count_df$token_id[1] & !(select_df$token_id %in% token_id) & select_df$processed=="no",]
						if(nrow(child)>0){
							select_part<-append(select_part,map_aggr(aggr_df$token[1],select_df[select_df$token_id==token_id[i],]$item))
							select_df[select_df$token_id==count_df$token_id[1],"processed"]<-"yes"
							select_df[select_df$token_id==token_id[i],"processed"]<-"yes"
							select_df[select_df$token_id==child$token_id[1],"processed"]<-"yes"
						}
					}
				}else{
					select_part<-append(select_part,map_aggr(aggr_df$token[1],select_df[select_df$token_id==token_id[i],]$item))
					select_df[select_df$token_id==aggr_df$token_id[1],"processed"]<-"yes"
					select_df[select_df$token_id==token_id[i],"processed"]<-"yes"
				}
			}else{	
				aggr_df<-select_df[select_df$head_token_id==select_df$head_token_id[as.integer(token_id[i])] & !(select_df$token_id %in% token_id) & tolower(select_df$token) %in% c("total","average","highest","lowest","best","worst") & select_df$processed=="no",]
				if(nrow(aggr_df)>0){
					select_part<-append(select_part,map_aggr(aggr_df$token[1],select_df[select_df$token_id==token_id[i],]$item))
					select_df[select_df$token_id==aggr_df$token_id[1],"processed"]<-"yes"
					select_df[select_df$token_id==token_id[i],"processed"]<-"yes"
				}else{
					select_part<-append(select_part,select_df[select_df$token_id==token_id[i],]$item)
					select_df[select_df$token_id==token_id[i],"processed"]<-"yes"
				}
			}
		}
	}
	gc()
	return(select_part)
}

translate_token<-function(token,discourse){
	if(tolower(token) %in% c("greater","higher","larger")){
		if(discourse){
			oper<-" <= "
		}else{
			oper<-" > "
		}
	}else if(tolower(token) %in% c("less","lower","smaller")){
		if(discourse){
			oper<-" >= "
		}else{
			oper<-" < "
		}
	}else if(tolower(token) %in% c("equals","equal")){
		if(discourse){
			oper<-" <> "
		}else{
			oper<-" = "
		}
	}else{
		oper<-""
	}
	return(oper)
}

get_having<-function(where_df,root){
	# We get here if root is obj and processed column is set to "no"
	having_part<-vector()
	select_aggr<-vector()
	if(root$itemtype=="column"){
		kids<-where_df[where_df$head_token_id==root$token_id & where_df$itemtype=="" & where_df$itemtype=="" & where_df$processed=="no",]
		if(nrow(kids)>0){
			for(i in 1:nrow(kids)){
				kids<-where_df[where_df$head_token_id==root$token_id & where_df$itemtype=="" & where_df$itemtype=="" & where_df$processed=="no",]
				if(nrow(kids)>0){
					kid=kids[1,]
				}else{
					break
				}
				kid1<-kid[tolower(kid$token) %in% c("total","average"),]
				if(nrow(kid1)>0){
					kid2<-kids[tolower(kids$token) %in% c("greater","higher","larger","less","lower","smaller","equals","equal"),]
					if(nrow(kid2)>0){
						# regular where
						oper<-translate_token(kid2$token[1],discourse=FALSE)
						if(oper!=""){
							grandchild<-where_df[where_df$head_token_id==kid2$token_id[1] & where_df$dep_rel=="obl" & where_df$xpos=="CD" & where_df$processed=="no",]
							if(nrow(grandchild)>0){
								having_part<-append(having_part,paste0(map_aggr(kid1$token[1],root$item),oper,grandchild$token[1]))
								where_df[where_df$token_id==kid2$token_id[1],"processed"]<-"yes"
								where_df[where_df$token_id==kid1$token_id[1],"processed"]<-"yes"
								where_df[where_df$token_id==grandchild$token_id[1],"processed"]<-"yes"
								where_df[where_df$token_id==root$token_id,"processed"]<-"yes"
							}else{
								grandchild<-where_df[where_df$head_token_id==kid2$token_id[1] & where_df$dep_rel=="obl" & where_df$itemtype=="column" & where_df$processed=="no",]
								if(nrow(grandchild)>0){
									greatgrandchild<-where_df[where_df$head_token_id==grandchild$token_id[1] & tolower(where_df$token) %in% c("total","average") & where_df$processed=="no",]
									if(nrow(greatgrandchild)>0){
										having_part<-append(having_part,paste0(map_aggr(kid1$token[1],root$item),oper,map_aggr(greatgrandchild$token[1],grandchild$item[1])))
										where_df[where_df$token_id==kid2$token_id[1],"processed"]<-"yes"
										where_df[where_df$token_id==kid1$token_id[1],"processed"]<-"yes"
										where_df[where_df$token_id==grandchild$token_id[1],"processed"]<-"yes"
										where_df[where_df$token_id==greatgrandchild$token_id[1],"processed"]<-"yes"
										where_df[where_df$token_id==root$token_id,"processed"]<-"yes"
									}else{
										having_part<-append(having_part,paste0(map_aggr(kid1$token[1],root$item),oper,grandchild$item[1]))
										having_part<-append(having_part,paste0(map_aggr(kid1$token[1],root$item),oper,map_aggr(greatgrandchild$token[1],grandchild$item[1])))
										where_df[where_df$token_id==kid2$token_id[1],"processed"]<-"yes"
										where_df[where_df$token_id==kid1$token_id[1],"processed"]<-"yes"
										where_df[where_df$token_id==grandchild$token_id[j],"processed"]<-"yes"
										where_df[where_df$token_id==root$token_id,"processed"]<-"yes"
									}
								}
							}
						}
					}else{
						# add aggregate function to select_aggr
						select_aggr<-append(select_aggr,map_aggr(kid1$token[1],root$item))
						where_df[where_df$token_id==kid1$token_id[1],"processed"]<-"yes"
						where_df[where_df$token_id==root$token_id,"processed"]<-"yes"		
					}
				}else{
					# Temporary assignment to skip processing
					where_df[where_df$token_id==kid$token_id,"processed"]<-"maybe"
				}				
			}
		}
	}else if(root$itemtype==""){
		if(tolower(root$token) %in% c("number","count")){
			kids<-where_df[where_df$head_token_id==root$token_id & where_df$itemtype=="column" & where_df$dep_rel %in% c("nmod") & where_df$processed=="no",]
			if(nrow(kids)>0){
				for(i in nrow(kids)){
					grandchild<-where_df[where_df$head_token_id==kids$token_id[i] & tolower(where_df$token) %in% c("greater","higher","larger","less","lower","smaller","equals","equal"),]
					if(nrow(grandchild)>0){
						oper<-translate_token(grandchild$token[1],discourse=FALSE)
						greatgrandchild<-where_df[where_df$head_token_id==grandchild$token_id[1] & where_df$dep_rel=="obl" & where_df$xpos=="CD" & where_df$processed=="no",]
						if(nrow(greatgrandchild)>0){
							having_part<-append(having_part,paste0("UniqueCount(",kids$item[i],")",oper,greatgrandchild$token[1]))
							where_df[where_df$token_id==kids$token_id[i],"processed"]<-"yes"
							where_df[where_df$token_id==grandchild$token_id[1],"processed"]<-"yes"
							where_df[where_df$token_id==greatgrandchild$token_id[1],"processed"]<-"yes"
							where_df[where_df$token_id==root$token_id,"processed"]<-"yes"
						}
					}else{
						sibling<-where_df[where_df$head_token_id==root$head_token_id[i] & tolower(where_df$token) %in% c("greater","higher","larger","less","lower","smaller","equals","equal"),]
						if(nrow(sibling)>0){
							oper<-translate_token(sibling$token[1],discourse=FALSE)
							child<-where_df[where_df$head_token_id==sibling$token_id[1] & where_df$dep_rel=="obl" & where_df$xpos=="CD" & where_df$processed=="no",]
							if(nrow(child)>0){
								having_part<-append(having_part,paste0("UniqueCount(",kids$item[i],")",oper,child$token[1]))
								where_df[where_df$token_id==kids$token_id[i],"processed"]<-"yes"
								where_df[where_df$token_id==sibling$token_id[1],"processed"]<-"yes"
								where_df[where_df$token_id==child$token_id[1],"processed"]<-"yes"
								where_df[where_df$token_id==root$token_id,"processed"]<-"yes"
							}
						}
					}
				}
			}
		}
		
	}
	# Restore unprocessed nodes
	where_df[where_df$processed=="maybe","processed"]<-"no"
	myList<-list()
	myList[[1]]<-where_df
	myList[[2]]<-having_part
	myList[[3]]<-select_aggr
	gc()
	return(myList)
}

validate_like<-function(token){
	# Until wildcard implemented for RDF and other databases
	##if(grepl("%",token,fixed=TRUE) | grepl("_",token,fixed=TRUE))
	if(grepl("%",token,fixed=TRUE)){
		right_part<-paste0(" ?like ",token)
	}else{
		right_part<-paste0(" = ",token)
	}
	return(right_part)
}

expose_column<-function(tbls,joins,value,cur_values,threshold=0.9){
	library(igraph)
	library(stringdist)
	new_col<-vector()
	if(grepl("%",value,fixed=TRUE)){
		wildcard<-paste0("^",gsub("%","[A-z0-9_:punct:]*",value),"$")
		ind<-grep(wildcard, cur_values$Value, ignore.case=TRUE)
	}else{
		matches<-stringsim(tolower(cur_values$Value),tolower(value),method='jw', p=0.1)
		ind<-which(matches>=threshold & matches==max(matches))
	}
	col_rows <-unique(cur_values[ind,])
	if(nrow(col_rows)==1){
		new_col[1]<-col_rows$Column[1]
		new_col[2]<-col_rows$Value[1]
	}else if(nrow(col_rows)>1){
		new_tbls<-unique(col_rows$Table)
		if(length(new_tbls)>1){
			g<-graph_from_edgelist(as.matrix(joins[,1:2]),directed=FALSE)
			vertices<-unique(names(V(g)))
			new_tbls<-intersect(vertices,new_tbls)
			if(length(new_tbls)>0){
				distances<-distances(g,v=new_tbls,to=tbls)
				d<-apply(distances, 1, function(x) min(x[x!=0]) )
				my_row<-which(d==min(d) & is.finite(d))
				if(length(my_row)>0){
					new_tbl<-new_tbls[my_row[1]]
					new_col[1]<-col_rows[col_rows$Table==new_tbl,]$Column[1]
					new_col[2]<-col_rows[col_rows$Table==new_tbl,]$Value[1]
				}
			}
		}else{
			new_col[1]<-col_rows$Column[1]
			new_col[2]<-col_rows$Value[1]
		}
	}
	return(new_col)
}


get_where<-function(where_df,tbls,joins,cur_values){
	# top node
	where_part<-vector()
	group_part<-vector()
	having_part<-vector()
	select_aggr<-vector()
	exposed_cols<-vector()
	if(nrow(where_df)>0){
		where_df$processed="no"
		top_nodes<-where_df[!(where_df$head_token_id %in% where_df$token_id) & !(where_df$dep_rel %in% c("case","cc")) & where_df$processed=="no",]
		token_id<-top_nodes[substr(top_nodes$xpos,1,2)=="VB",]$token_id
		if(length(token_id)>0){
			where_df<-where_df[!(where_df$token_id %in% token_id),]
			if(nrow(where_df)>0){
				top_nodes<-where_df[!(where_df$head_token_id %in% where_df$token_id) & !(where_df$dep_rel %in% c("case","cc")) & where_df$processed=="no",]
			}
		}
		n<-nrow(top_nodes)
		if(n>0){
			for(i in 1:n){
				r<-get_having(where_df,top_nodes[i,])
				where_df<-r[[1]]
				having_part<-append(having_part,r[[2]])
				select_aggr<-append(select_aggr,r[[3]])
			}
		}
		# Refresh top nodes after having clause processing
		top_nodes<-where_df[!(where_df$head_token_id %in% where_df$token_id) & !(where_df$dep_rel %in% c("case","cc")) & where_df$processed=="no",]
		while(nrow(top_nodes)>0){
			node<-top_nodes[1,]
			# included root/acl:relcl as it can be potential column value
			if(node$dep_rel %in% c("nmod","conj","obl","obj","root","acl:relcl","xcomp") & node$xpos!="JJR" & substr(node$xpos,1,2)!="VB" & node$itemtype!="column"){
				child<-where_df[where_df$head_token_id==node$token_id & where_df$itemtype=="column" & where_df$processed=="no",]
				if(nrow(child)>0){
					right_part<-validate_like(node$token)
					where_part<-append(where_part,paste0(child$item[1],right_part))
					where_df[where_df$token_id==child$token_id[1],"processed"]<-"yes"
				}else{
					compare<-where_df[where_df$dep_rel=="conj" & where_df$xpos=="JJR" & where_df$processed=="no",]
					if(nrow(compare)>0){
						nocompare<-where_df[where_df$head_token_id==compare$token_id[1] & tolower(where_df$token) %in% c("not","no") & where_df$processed=="no",]
						discourse<-!nrow(nocompare)==0
						oper<-translate_token(compare$token[1],discourse)
						child<-where_df[where_df$head_token_id==compare$token_id & where_df$itemtype=="column" & where_df$processed=="no",]
						if(nrow(child)>0){
							where_part<-append(where_part,paste0(child$item[1],oper,node$token))
							where_df[where_df$token_id==child$token_id[1],"processed"]<-"yes"
						}
						where_df[where_df$token_id==compare$token_id[1],"processed"]<-"yes"
					}else{
						# Here is the place where we can determine potential column name by matching
						# value node$token to a column that contains such a value for strings
						# if value is non numeric
						# single quotes indicate that it is not a values of a column to lookup
						if(substr(node$source,1,1)!="'" & substr(node$source,nchar(node$source),nchar(node$source))!="'"){
							options(warn=-1)
							if(is.na(as.numeric(node$token))){	
								new_col<-expose_column(tbls,joins,node$token,cur_values)
								if(length(new_col)==2){							
									if(grepl("%",node$token,fixed=TRUE)){
										oper<-" ?like "
										new_col[2]<-node$token
									}else{
										oper<-" = "
									}
									exposed_cols<-append(exposed_cols,new_col[1])
									where_part<-append(where_part,paste0(new_col[1],oper,gsub(" ","_",new_col[2])))
								}
							}
							options(warn=0)
						}
					}
				}
			}else if(node$xpos=="JJR" & node$itemtype!="column"){
				child<-where_df[where_df$head_token_id==node$token_id[1] & where_df$dep_rel=="obl" & where_df$xpos=="CD" & where_df$processed=="no",]
				if(nrow(child)>0){
					grandchild<-where_df[where_df$head_token_id==child$token_id[1] & where_df$itemtype=="column" & where_df$processed=="no",]
					if(nrow(grandchild)>0){
						grandchild2<-where_df[where_df$head_token_id==child$token_id[1] & tolower(where_df$token) %in% c("not","no") & where_df$processed=="no",]	
						discourse<-!nrow(grandchild2)==0
						oper<-translate_token(node$token[1],FALSE)
						if(oper!=""){
							where_part<-append(where_part,paste0(grandchild$item[1],oper,child$token[1]))
						}
						where_df[where_df$token_id==grandchild$token_id[1],"processed"]<-"yes"
					}else{
						sibling<-where_df[where_df$head_token_id==node$token_id & where_df$itemtype=="column" & where_df$processed=="no",]
						if(nrow(sibling)>0){
							sibling2<-where_df[where_df$head_token_id==node$token_id & tolower(where_df$token) %in% c("not","no") & where_df$processed=="no",]
							discourse<-!nrow(sibling2)==0
							oper<-translate_token(node$token[1],discourse)
							if(oper!=""){
								where_part<-append(where_part,paste0(sibling$item[1],oper,child$token))
							}
							where_df[where_df$token_id==sibling$token_id[1],"processed"]<-"yes"
							if(discourse){
								where_df[where_df$token_id==sibling2$token_id[1],"processed"]<-"yes"
							}
						}
					}
					where_df[where_df$token_id==child$token_id[1],"processed"]<-"yes"
				}
			}else if(node$dep_rel %in% c("nmod","conj","compound") & node$itemtype=="column"){
				child<-where_df[where_df$head_token_id==node$token_id & where_df$itemtype!="column" & where_df$dep_rel %in% c("flat","fixed","compound","nummod") & where_df$processed=="no",]
				if(nrow(child)>0){
					right_part<-validate_like(child$token[1])
					where_part<-append(where_part,paste0(node$item,right_part))
					#where_part<-append(where_part,paste0(node$item," = ",child$token[1]))
					where_df[where_df$token_id==child$token_id[1],"processed"]<-"yes"
				}else{
					child<-where_df[where_df$head_token_id==node$token_id & where_df$itemtype!="column" & where_df$dep_rel %in% c("amod") & where_df$xpos=="JJ" & where_df$processed=="no",]
					if(nrow(child)>0){
						right_part<-validate_like(child$token[1])
						where_part<-append(where_part,paste0(node$item,right_part))
						#where_part<-append(where_part,paste0(node$item," = ",child$token[1]))
						where_df[where_df$token_id==child$token_id[1],"processed"]<-"yes"
					}else{
						child<-where_df[where_df$head_token_id==node$token_id & where_df$itemtype!="column" & where_df$dep_rel %in% c("amod","advmod") & where_df$xpos=="JJR" & where_df$processed=="no",]
						if(nrow(child)>0){
							nephew<-where_df[where_df$head_token_id==child$token_id[1] & where_df$dep_rel=="obl" & where_df$xpos=="CD" & where_df$processed=="no",]
							if(nrow(nephew)>0){				
								niece<-where_df[where_df$head_token_id==child$token_id[1] & tolower(where_df$token) %in% c("not","no") & where_df$processed=="no",]
								discourse<-!nrow(niece)==0
								oper<-translate_token(child$token[1],discourse)
								if(oper!=""){
									where_part<-append(where_part,paste0(node$item,oper,nephew$token[1]))
								}
								where_df[where_df$token_id==nephew$token_id[1],"processed"]<-"yes"
								if(discourse){
									where_df[where_df$token_id==niece$token_id[1],"processed"]<-"yes"
								}
							}
							where_df[where_df$token_id==child$token_id[1],"processed"]<-"yes"
						}else{
							sibling<-where_df[where_df$head_token_id==node$head_token_id & where_df$dep_rel=="amod" & where_df$xpos=="JJR" & where_df$processed=="no",]
							if(nrow(sibling)>0){
								nephew<-where_df[where_df$head_token_id==sibling$token_id[1] & where_df$dep_rel=="obl" & where_df$xpos=="CD" & where_df$processed=="no",]
								if(nrow(nephew)>0){
									niece<-where_df[where_df$head_token_id==sibling$token_id[1] & tolower(where_df$token) %in% c("not","no") & where_df$processed=="no",]
									discourse<-!nrow(niece)==0
									oper<-translate_token(sibling$token[1],discourse)
									if(oper!=""){
										where_part<-append(where_part,paste0(node$item,oper,nephew$token[1]))
									}
									where_df[where_df$token_id==nephew$token_id[1],"processed"]<-"yes"
									if(discourse){
										where_df[where_df$token_id==niece$token_id[1],"processed"]<-"yes"
									}
								}
								where_df[where_df$token_id==sibling$token_id[1],"processed"]<-"yes"
							}else{
								cousin<-where_df[where_df$head_token_id==node$head_token_id & where_df$xpos=="JJR" & where_df$processed=="no",]
								if(nrow(cousin)>0){
									nephew<-where_df[where_df$head_token_id==cousin$token_id[1] & where_df$dep_rel=="obl" & where_df$xpos=="CD" & where_df$processed=="no",]
									if(nrow(nephew)>0){
										niece<-where_df[where_df$head_token_id==cousin$token_id[1] & tolower(where_df$token) %in% c("not","no") & where_df$processed=="no",]
										discourse<-!nrow(niece)==0
										oper<-translate_token(cousin$token[1],discourse)
										if(oper!=""){
											where_part<-append(where_part,paste0(node$item,oper,nephew$token[1]))
										}
										where_df[where_df$token_id==nephew$token_id[1],"processed"]<-"yes"
										if(discourse){
											where_df[where_df$token_id==niece$token_id[1],"processed"]<-"yes"
										}
									}
									where_df[where_df$token_id==cousin$token_id[1],"processed"]<-"yes"
								}else{
									group_part<-append(group_part,node$item)
									where_df[where_df$token_id==node$token_id,"processed"]<-"yes"
								}
							}
						}
					}
						
				}
			}else if(node$dep_rel=="obj" & node$itemtype=="column"){
				child<-where_df[where_df$head_token_id==node$token_id & tolower(where_df$token) %in% c("best","highest","worst","lowest") & where_df$processed=="no",]
				if(nrow(child)>0){
					where_part<-append(where_part,paste0(node$item,"=", map_aggr(child$token[1],node$item)))
					where_df[where_df$token_id==child$token_id[1],"processed"]<-"yes"
				}else{
					child<-where_df[where_df$head_token_id==node$token_id & where_df$dep_rel=="amod" & where_df$xpos=="JJR" & where_df$processed=="no",]
					if(nrow(child)>0){
						grandchild<-where_df[where_df$head_token_id==child$token_id[1] & where_df$dep_rel=="obl" & where_df$xpos=="CD" & where_df$processed=="no",]
						if(nrow(grandchild)>0){
							grandchild2<-where_df[where_df$head_token_id==child$token_id[1] & tolower(where_df$token) %in% c("not","no") & where_df$processed=="no",]
							discourse<-!nrow(grandchild2)==0
							oper<-translate_token(child$token[1],discourse)
							if(oper!=""){
								where_part<-append(where_part,paste0(node$item,oper,grandchild$token[1]))
							}
							where_df[where_df$token_id==grandchild$token_id[1],"processed"]<-"yes"
							if(discourse){
								where_df[where_df$token_id==grandchild2$token_id[1],"processed"]<-"yes"
							}
						}else{
							grandchild<-where_df[where_df$head_token_id==child$token_id[1] & where_df$dep_rel=="obl" & where_df$itemtype=="column" & where_df$processed=="no",]
							if(nrow(grandchild)>0){
								grandchild2<-where_df[where_df$head_token_id==child$token_id[1] & tolower(where_df$token) %in% c("not","no") & where_df$processed=="no",]
								discourse<-!nrow(grandchild2)==0
								oper<-translate_token(child$token[1],discourse)
								if(oper!=""){
									where_part<-append(where_part,paste0(node$item,oper,grandchild$item[1]))
								}
								where_df[where_df$token_id==grandchild$token_id[1],"processed"]<-"yes"
								if(discourse){
									where_df[where_df$token_id==grandchild2$token_id[1],"processed"]<-"yes"
								}
							}
						}
						where_df[where_df$token_id==child$token_id[1],"processed"]<-"yes"
					}else {
						child<-where_df[where_df$head_token_id==node$token_id & where_df$dep_rel=="nmod" & where_df$xpos=="CD" & where_df$processed=="no",]
						if(nrow(child)>0){
							grandchild<-where_df[where_df$head_token_id==child$token_id[1] & where_df$dep_rel %in% c("compound","conj") & where_df$xpos=="CD" & where_df$processed=="no",]
							if(nrow(grandchild)>0){
								where_part<-append(where_part,paste0(node$item," between ",child$token[1]," and ",grandchild$token[1]))
								where_df[where_df$token_id==grandchild$token_id[1],"processed"]<-"yes"
							}
							where_df[where_df$token_id==child$token_id[1],"processed"]<-"yes"
						}else{
							sibling<-where_df[where_df$head_token_id==node$head_token_id & where_df$dep_rel %in% c("xcomp") & where_df$processed=="no",]
							if(nrow(sibling)>0){
								where_part<-append(where_part,paste0(node$item,"=", sibling$token[1]))
								where_df[where_df$token_id==sibling$token_id[1],"processed"]<-"yes"
							}
						}
					}
				}
			}else if(node$dep_rel=="obl" & node$itemtype=="column"){
				child<-where_df[where_df$head_token_id==node$token_id & tolower(where_df$token) %in% c("by") & where_df$processed=="no",]
				if(nrow(child)>0){
					group_part<-append(group_part,node$item)
				}else{
					child<-where_df[where_df$head_token_id==node$token_id & where_df$itemtype!="column" & where_df$dep_rel %in% c("amod","advmod") & where_df$processed=="no",]
					if(nrow(child)>0){
						where_part<-append(where_part,paste0(node$item,"=", child$token[1]))
						where_df[where_df$token_id==child$token_id[1],"processed"]<-"yes"
					}
				}
			}
			where_df[where_df$token_id==node$token_id,"processed"]<-"yes"
			top_nodes<-where_df[!(where_df$head_token_id %in% where_df[where_df$processed=="no",]$token_id) & !(where_df$dep_rel %in% c("case","cc")) & where_df$processed=="no",]
		}
	}
	r<-myList<-list()
	r[[1]]<-where_part
	r[[2]]<-group_part
	r[[3]]<-having_part
	r[[4]]<-select_aggr
	r[[5]]<-exposed_cols
	return(r)
}

map_aggr<-function(aggr,colname){
	if(length(aggr)>0){
		if(tolower(aggr)=="total"){
			r<-paste0("Sum(",colname,")")
		}else if(tolower(aggr)=="average"){
			r<-paste0("Avg(",colname,")")
		}else if(tolower(aggr) %in% c("lowest","worst")){
			r<-paste0("Min(",colname,")")
		}else if(tolower(aggr) %in% c("highest","best")){
			r<-paste0("Max(",colname,")")
		}else if(tolower(aggr)=="many"){
			r<-paste0("UniqueCount(",colname,")")
		}else{
			r<-colname
		}
	}else{
		r<-colname
	}
	return(r)
}

get_subtree<-function(df,leaves,excl=vector()){
# Get a subtree with starting node index ind
	out<-df[0,]
	if(all(leaves)>=0 & all(leaves) <= nrow(df)){
		while(length(leaves)>0){
			out<-rbind(out,df[df$token_id %in% leaves,])
			leaves<-df[df$head_token_id %in% leaves & !(df$dep_rel %in% excl) & !(df$token_id %in% out$token_id),]$token_id
		}
	}
	return(out)	
}

parse_request<-function(df_in,db){
	# to handle column names that are not nouns or adjectives 
	df1<-tag_dbitems(df_in,db)
	df1$source<-df1$token
	df<-refine_parsing(df1)
	gc()
	return(df)
}

tag_dbitems<-function(df_in,db){
	df_in$itemtype<-""
	ind<-which(db$Word != "")
	mydf<-db[ind,]
	# make sure we keep the best score
	mydf<-mydf[order(mydf$Word,-mydf$Score,mydf$AppID),]
	mydf<-mydf[!duplicated(mydf$Word),]
	x<-as.data.frame(df_in$token)
	y<-mydf$Column[match(unlist(x), mydf$Word)]
	z<-mydf$Datatype[match(unlist(x), mydf$Word)]
	y[is.na(y)]<-""
	z[is.na(z)]<-""
	df_in$item<-y
	df_in$itemdatatype<-z
	df_in[df_in$item != "","itemtype"]<-"column"
	return(df_in)
}

parse_question<-function(txt){
	FILE_MODEL<-"english-ud-2.0-170801.udpipe"
	library(udpipe)
	
	if(!exists("tagger")){
		tagger <<- udpipe_load_model(FILE_MODEL)
	}
	doc <- tryCatch({
		udpipe_annotate(tagger, txt)
	}, error = function(e) {
		return(NULL)
	})
	if(is.null(doc)){
		tagger <<- udpipe_load_model(FILE_MODEL)
		doc <- udpipe_annotate(tagger, txt)
	}
	df<-as.data.frame(doc)
	gc()
	return(df[,4:12])
}

parse_question_mgr<-function(txt){
	STOPWORDS<-c("a","the","here","there","it","he","she","they","which","what","who","and")
	FIRSTWORDS<-c("select","show","display","present","list","find","locate")
	
	# update text by removing stop words
	words<-unlist(strsplit(txt," "))
	if(length(words)>0){
		if(tolower(words[1]) %in% FIRSTWORDS){
			words<-words[-1]
		}
	}
	words<-words[!(tolower(words) %in% STOPWORDS)]
	words<-replace_words(words)
	
	# Removing "-","_" to have the correct annotation
	z<-sapply(words,function(w) gsub("[-_'%]","",w))
	mytxt<-paste(z,collapse=" ")
	df<-parse_question(tolower(mytxt))
	if(nrow(df)>0){
		for(i in 1:nrow(df)){
			token<-df$token[i]
			y<-which(token==tolower(z))
			if(length(y)>0){
				df[i,"token"]<-names(z[y[1]])
				z<-z[-y[1]]
			}
		}
	}else{
		df<-data.frame()
	}
	return(df)
}

replace_words<-function(words){
	orig=c("mean","less","lower")
	repl=c("average","smaller","smaller")
	n<-min(length(orig),length(repl))
	for(i in 1:n){
		ind<-which(tolower(words)==orig[i])
		if(length(ind)>0){
			words[ind]<-repl[i]
		}
	}
	return(words)
}

is_nlp_reserved<-function(words){
	STOPWORDS<-c("not","no","best","highest","worst","lowest","greater","higher","larger","less","lower","smaller","equals","equal","total","average","highest","lowest","best","worst","many","number","count")
	return(any(tolower(words) %in% STOPWORDS))
}

remove_nlp_reserved<-function(words){
	# if nlp stoplist no neighbors needed
	STOPWORDS<-c("not","no","best","highest","worst","lowest","greater","higher","larger","less","lower","smaller","equals","equal","total","average","highest","lowest","best","worst","many","number","count")
	out<-words[!(tolower(words) %in% STOPWORDS)]
	return(out)
}

filter_apps<-function(df_in,db,threshold=0.9){
	STOPWORDS<-c("not","no","best","highest","worst","lowest","greater","higher","larger","less","lower","smaller","equals","equal","total","average","highest","lowest","best","worst","many","number","count")
	library(plyr)
	n<-nrow(df_in)
	if(n>0){
		db$Word<-""
		db$Score<-0
		ind<-which(substr(df_in$token,1,1)!="'" & substr(df_in$token,nchar(df_in$token),nchar(df_in$token))!="'" & substr(df_in$xpos,1,2) %in% c("NN","JJ"))
		ind2<-which(!(df_in$token %in% STOPWORDS))
		idx<-intersect(ind,ind2)
		matches<-1-stringdistmatrix(tolower(df_in$token[idx]),tolower(db$Column),method='jw', p=0.1)
		x<-which(matches>threshold,arr.ind=T)
		# if multiple db columns matching a word the highest scoring is match is selected
		z<-as.data.frame(x)
		z$score<-matches[x]
		z<-z[order(z$col,-z$score),]
		a<-as.matrix(z[!duplicated(z[,2]),1:2])
		db[a[,2],"Word"]=df_in$token[idx[a[,1]]]
		db[a[,2],"Score"]=matches[a]	
	}	
	df_apps<-unique(db[db$Word != "",c("AppID","Word")])
	df_apps<-count(df_apps,"AppID")
	
	if(nrow(df_apps)>0){
		max_freq<-max(df_apps$freq)
		apps<-df_apps[df_apps$freq==max_freq,"AppID"]
		global_apps<-df_apps$AppID
	}else{
		max_freq<-0
		apps<-vector()
		global_apps<-vector()
	}
	myList<-list()
	myList[[1]]<-apps
	myList[[2]]<-db[db$AppID %in% global_apps,]
	myList[[3]]<-global_apps
	myList[[4]]<-max_freq
	gc()
	return(myList)
}

refine_parsing<-function(df){
	ind<-as.integer(df[df$itemtype %in% c("column","table") & !(substr(df$xpos,1,2) %in% c("NN","JJ")) & df$dep_rel!="amod","token_id"])
	if(length(ind)>0){
		mydf<-df
		mydf$token[ind]<-"epiphany"
		mytxt<-paste(mydf$token,collapse=" ")
		mydf<-parse_question_mgr(mytxt)
		df[,5:9]<-mydf[,5:9]
	}
	# Remove first and last ' if exist
	df$token<-sapply(df$token,function(w) gsub("^'|'$", '',w))
	gc()
	return(df)
}

optimize_joins<-function(cols,joins,cur_db){
	# get the existing tables with required columns
	if(nrow(joins)>0){
		tbls<-as.character(unique(cur_db[tolower(cur_db$Column) %in% tolower(cols),"Table"]))
		# if all columns exist in a single table just take this table
		ind<-which(unlist(lapply(tbls, function(x) all(tolower(cols) %in% tolower(cur_db[cur_db$Table==x,"Column"])))))
		if(length(ind)>0){
			tbls<-tbls[ind[1]]
		}
		if(length(tbls)==1){
			# if all columns in a single table
			items<-unlist(strsplit(tbls,"._.",fixed=TRUE))
			joins<-joins[0,]
			joins<-rbindlist(list(joins,list(tbls,tbls,"","",items[1],items[1])))
			#colnames(joins)<-c("tbl1","tbl2","joinby1","joinby2","AppID","AppID2")
		}else if(length(tbls)>1){
			mytbls<-connect_tables(tbls,joins)
			# keep only joins that contain only required tables
			joins<-joins[(joins$tbl1 %in% mytbls) & (joins$tbl2 %in% mytbls),]
			# minimize joins
			if(nrow(joins)>0){
				joins<-drop_extra_links(cols,joins,cur_db)
			}
		}else{
			joins<-vector()
		}
		gc()
	}
	return(joins)
}

drop_extra_links<-function(cols,joins,cur_db){
	# if combined databases drop extra links if possible
	g<-graph_from_edgelist(as.matrix(joins[,1:2]),directed=FALSE)
	nodes_df<-as.data.frame(unique(names(V(g))),stringsAsFactors=FALSE)
	names(nodes_df)<-"node"
	nodes_df$label<-unlist(strsplit(nodes_df$node,"._.",fixed=TRUE))[c(FALSE,TRUE)]
	
	edges_df<-joins[,1:2]
	# add terminal column nodes
	join_cols<-vector()
	for(i in 1:length(cols)){
		# identify tables with the current column
		col_tbls<-cur_db[cur_db$Table %in% nodes_df$node & cur_db$Column==cols[i],"Table"]
		if(length(col_tbls)>0){
			# get tables and labels from node_df
			col_df<-nodes_df[nodes_df$node %in% col_tbls,]
			names(col_df)<-c("tbl1","tbl2")
			edges_df<-rbind(edges_df,col_df)
			join_cols<-unique(append(join_cols,col_df$tbl2))
		}
	}
	# remove circular links
	edges_df<-edges_df[edges_df$tbl1 != edges_df$tbl2,]
	if(length(join_cols)==1){
		tbls<-edges_df[1,"tbl1"]
		items<-unlist(strsplit(tbls,"._.",fixed=TRUE))
		joins<-joins[0,]
		joins<-rbindlist(list(joins,list(tbls,tbls,"","",items[1],items[1])))
	}else{
		g1<-graph_from_edgelist(as.matrix(edges_df),directed=FALSE)
		cols_id<-which(V(g1)$name %in% join_cols)	
		stree<-steinertree(type = "RSP", optimize = TRUE,terminals = cols_id,graph = g1,color = FALSE, merge = FALSE) 
		if(length(stree)==1){
			new_joins<-as.data.frame(as_edgelist(stree[[1]],names=TRUE),stringsAsFactors=FALSE)
			names(new_joins)<-c("tbl1","tbl2")
			new_joins<- new_joins[!(new_joins$tbl1 %in% join_cols) & !(new_joins$tbl2 %in% join_cols),]
			# run mst to make sure there are no extra edges!
			g1<-graph_from_edgelist(as.matrix(new_joins),directed=FALSE)
			g2<-mst(g1)
			new_joins<-as.data.frame(as_edgelist(g2,names=TRUE),stringsAsFactors=FALSE)
			names(new_joins)<-c("tbl1","tbl2")
			
			arranged_joins<-joins[0,]
			for(j in 1:nrow(new_joins)){
				x<-joins[joins$tbl1==new_joins$tbl1[j] & joins$tbl2==new_joins$tbl2[j],]
				if(nrow(x)>0){
					arranged_joins<-rbind(arranged_joins,x)
				}else{
					x<-joins[joins$tbl2==new_joins$tbl1[j] & joins$tbl1==new_joins$tbl2[j],]
					if(nrow(x)>0){
						arranged_joins<-rbind(arranged_joins,x)
					}
				}
			}
			new_joins<-arranged_joins
			# add other columns from original joins!!!
			tbl1<-unlist(strsplit(new_joins$tbl1,"._.",fixed=TRUE))
			tbl2<-unlist(strsplit(new_joins$tbl2,"._.",fixed=TRUE))
			new_joins$joinby1<-tbl1[c(FALSE,TRUE)]
			new_joins$joinby2<-tbl2[c(FALSE,TRUE)]
			new_joins$AppID<-tbl1[c(TRUE,FALSE)]
			new_joins$AppID2<-tbl2[c(TRUE,FALSE)]
			joins<-new_joins
		}else{
			joins<-vector()
		}
	}
	gc()
	return(joins)
}

assign_weights<-function(joins){
	INTER<-2
	INTRA<-1
	all_edges_cnt<-nrow(joins)
	added_edges_cnt<-nrow(joins[joins$AppID != joins$AppID2,])
	weights<-c(rep(INTRA,all_edges_cnt-added_edges_cnt),rep(INTER,added_edges_cnt))
	return(weights)
}

connect_tables_alt<-function(tbls,joins){
	if(length(tbls)>1){
		g<-graph_from_edgelist(as.matrix(joins[,1:2]),directed=FALSE)
		vertices<-unique(names(V(g)))
		if(length(intersect(vertices,tbls))>0){
			myweights<-assign_weights(joins)
			# which tbls in our db
			tbls<-intersect(vertices,tbls)
			if(length(tbls)>1){	
				distances<-distances(g,v=tbls,to=tbls)
				n<-nrow(distances)
				for(i in 1:(n-1)){
					for(j in (i+1):n){
						if(is.finite(distances[i,j])){
							if(distances[i,j]>1){
								paths<-all_shortest_paths(g,from=tbls[i],to=tbls[j],weights=myweights)[[1]]
								tbls<-unique(append(tbls,names(unlist(paths))))
							}
						}
					}
				}
			}else if(length(tbls)==0){
				tbls<-vector()
			}
		}else{
			tbls<-vector()
		}
	}
	gc()
	return(tbls)
}

connect_tables<-function(tbls,joins){
	if(length(tbls)>1){
		g<-graph_from_edgelist(as.matrix(joins[,1:2]),directed=FALSE)
		vertices<-unique(names(V(g)))
		if(length(intersect(vertices,tbls))>0){
			myweights<-assign_weights(joins)
			# which tbls in our db
			tbls<-intersect(vertices,tbls)
			if(length(tbls)>1){	
				distances<-distances(g,v=tbls,to=tbls)
				n<-nrow(distances)
				for(i in 1:(n-1)){
					for(j in (i+1):n){
						if(is.finite(distances[i,j])){
							if(distances[i,j]>1){
								paths<-all_shortest_paths(g,from=tbls[i],to=tbls[j],weights=myweights)[[1]]
								lengths<-sapply(paths, length)
								idx<-which(lengths==min(lengths))
								m<-length(idx)
								min_cnt<-0
								for(k in 1:m){
									cnt<-length(which(!(names(paths[[idx[k]]]) %in% tbls)))
									if(k==1 | cnt < min_cnt){
										min_idx<-k
										min_cnt<-cnt
									}
								}
								tbls<-unique(append(tbls,names(paths[[idx[min_idx]]])))
							}
						}
					}
				}
			}else if(length(tbls)==0){
				tbls<-vector()
			}
		}else{
			tbls<-vector()
		}
	}
	gc()
	return(tbls)
}

verify_joins<-function(cols,joins,cur_db){
	
	myList<-list()
	myList[[1]]<-""
	g<-graph_from_edgelist(as.matrix(joins[,1:2]),directed=FALSE)
	g_mst<-mst(g)
	# verify that all required columns accessible
	tbls<-vertex_attr(g_mst)$name
	tbls_cols<-as.character(cur_db[tolower(cur_db$Table) %in% tolower(tbls),"Column"])
	if(all(tolower(cols) %in% tolower(tbls_cols))){
		myList[[2]]<-joins
	}else{
		myList[[1]]<-"Rephrase the request: could not join all required tables"
	}
	gc()
	return(myList)
}

build_join_clause<-function(joins){
	n<-nrow(joins)
	clause<-""
	from_joins<-data.table(tbl1=character(),tbl2=character(),joinby1=character(),joinby2=character())
	if(n>0){
		if(joins[1,"tbl1"]==joins[1,"tbl2"]){
			clause<-as.character(joins[1,"tbl1"])
			from_joins<-rbindlist(list(from_joins,list(clause,"","","")))
		}else{
			joins$processed<-"no"
			joins$id<-seq(1:n)
			tbls<-vector()
			tbls[1]<-as.character(joins[1,"tbl1"])
			clause<-as.character(joins[1,"tbl1"])
			from_joins<-rbindlist(list(from_joins,list(clause,"","","")))
			while(nrow(joins[(tolower(joins$tbl1) %in% tolower(tbls) | tolower(joins$tbl2) %in% tolower(tbls) ) & joins$processed == "no",])>0){
				cur_rec<-joins[(tolower(joins$tbl1) %in% tolower(tbls) | tolower(joins$tbl2) %in% tolower(tbls) )  & joins$processed == "no",][1,]
				if(length(tbls[tolower(cur_rec$tbl1) %in% tolower(tbls)])>0){
					if(length(tbls[tolower(cur_rec$tbl2) %in% tolower(tbls)])>0){
						clause<-paste0(clause, "on ",cur_rec$tbl1,".",cur_rec$joinby1,"=",cur_rec$tbl2,".",cur_rec$joinby2)
						from_joins<-rbindlist(list(from_joins,list(cur_rec$tbl1,cur_rec$tbl2,cur_rec$joinby1,cur_rec$joinby2)))
					}else{
						tbls[length(tbls)+1]<-cur_rec$tbl2
						clause<-paste0(clause," inner join ",cur_rec$tbl2," on ",cur_rec$tbl1,".",cur_rec$joinby1,"=",cur_rec$tbl2,".",cur_rec$joinby2)
						from_joins<-rbindlist(list(from_joins,list(cur_rec$tbl1,cur_rec$tbl2,cur_rec$joinby1,cur_rec$joinby2)))
					}
				}else{
					tbls[length(tbls)+1]<-cur_rec$tbl1
					clause<-paste0(clause," inner join ",cur_rec$tbl1," on ",cur_rec$tbl2,".",cur_rec$joinby1,"=",cur_rec$tbl1,".",cur_rec$joinby2)
					from_joins<-rbindlist(list(from_joins,list(cur_rec$tbl1,cur_rec$tbl2,cur_rec$joinby1,cur_rec$joinby2)))
				}
				joins[cur_rec$id,"processed"]<-"yes"
			}
		}
	}
	from_joins$tbl1=as.character(from_joins$tbl1)
	from_joins$tbl2=as.character(from_joins$tbl2)
	from_joins$joinby1=as.character(from_joins$joinby1)
	from_joins$joinby2=as.character(from_joins$joinby2)
	myList<-list()
	myList[[1]]<-clause
	myList[[2]]<-from_joins
	return(myList)
}	

join_clause_mgr<-function(cols,cur_db,joins){
	library(plyr)
	myList<-list()
	joins<-optimize_joins(cols,joins,cur_db)
	if(nrow(joins)>0){
		out<-verify_joins(cols,joins,cur_db)
		if(out[[1]]==""){
			joins<-out[[2]]
			out<-build_join_clause(joins)
			myList[[1]]<-""
			myList[[2]]<-out[[1]]
			myList[[3]]<-out[[2]]
			myList[[4]]<-joins
		}else{
			myList[[1]]<-out[[1]]
		}
	}else{
		x<-cur_db[cur_db$Column %in% cols,]
		y<-count(x,"Table")
		z<-y[y$freq==length(cols),]
		if(nrow(z)>0){
			myList[[1]]<-""
			myList[[2]]<-z$Table[1]
			myList[[3]]<-data.frame(tbl1=z$Table[1],tbl2="",joinby1="",joinby2="",stringsAsFactors = FALSE)
			myList[[4]]<-joins
		}else{
			myList[[1]]<-"Reprase the request: could not locate required tables"
		}
	}
	gc()
	return(myList)
}

